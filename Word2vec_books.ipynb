{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb7e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from gensim.models import phrases\n",
    "import  matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import  Phraser,Phrases\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fa1a41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files():#Read All Text Files\n",
    "    \n",
    "    file=open(\"Siddhartha.txt\",encoding=\"utf8\")\n",
    "    corpus1=file.read()\n",
    "    file=open(\"The-Adventures-of-Sherlock-Holmes.txt\",encoding=\"utf8\")\n",
    "    corpus2=file.read()\n",
    "    file=open(\"If-Not-For-The-Knight.txt\",encoding=\"utf8\")\n",
    "    corpus3=file.read()\n",
    "    data=corpus1+corpus2+corpus3\n",
    "\n",
    "\n",
    "    return data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d7cc12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords=stopwords.words(\"english\")\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc62c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all unnasasary words\n",
    "def clean_data(sentence):\n",
    "    sentence=re.sub(r'[^A-Za-z0-9\\s.]',r'',str(sentence).lower())\n",
    "    sentence=re.sub(r'\\n',r'',sentence)\n",
    "    sentence=\" \".join([word for word in sentence.split() if word not in stopwords])\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ec3fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle data\n",
    "def suffle_data(sentence):\n",
    "    suffled=list(sentence)\n",
    "    random.shuffle(suffled)\n",
    "    return suffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83591476",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=read_files() #Save all in one variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b040ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.splitlines() #Split all lines\n",
    "data=list(filter(None,data)) #Remove blank data\n",
    "data=pd.DataFrame(data) #Convert in dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4bfa726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Project Gutenberg EBook of Siddhartha, by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Copyright laws are changing all over the world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This header should be the first thing seen whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Please read the “legal small print,” and other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>**Welcome To The World of Free Plain Vanilla E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>**eBooks Readable By Both Humans and By Comput...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>*****These eBooks Were Prepared By Thousands o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Title: Siddhartha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Author: Herman Hesse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Release Date: February, 2001 [EBook #2500] [Mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  The Project Gutenberg EBook of Siddhartha, by ...\n",
       "1  Copyright laws are changing all over the world...\n",
       "2  This header should be the first thing seen whe...\n",
       "3  Please read the “legal small print,” and other...\n",
       "4  **Welcome To The World of Free Plain Vanilla E...\n",
       "5  **eBooks Readable By Both Humans and By Comput...\n",
       "6  *****These eBooks Were Prepared By Thousands o...\n",
       "7                                  Title: Siddhartha\n",
       "8                               Author: Herman Hesse\n",
       "9  Release Date: February, 2001 [EBook #2500] [Mo..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33cf7e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]=data[0].map(lambda x:clean_data(x))  #Apply to clean data\n",
    "temp_corp=data[0].map(lambda x:x.split('.')) #Apply to split the sentence in word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20d53e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10377/10377 [00:00<00:00, 85918.41it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus=[] #append all word to corpus\n",
    "for i in tqdm(range(len(temp_corp))):\n",
    "    for line in temp_corp[i][:-1]:\n",
    "        word=[x for x in line.split()]\n",
    "        corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2546fca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of sentence 13985\n",
      "number of word 92452\n"
     ]
    }
   ],
   "source": [
    "number_of_sentence=len(corpus)\n",
    "number_word=0\n",
    "for i in corpus:\n",
    "    number_word+=len(i)\n",
    "print(\"number_of sentence\",number_of_sentence)\n",
    "print(\"number of word\",number_word)\n",
    "\n",
    "#To Detect common pharase and combine it in to single word\n",
    "phrases = Phrases(corpus, min_count=25, threshold=50)\n",
    "bigram = Phraser(phrases)\n",
    "\n",
    "for index,sentence in enumerate(corpus):\n",
    "    corpus[index]=bigram[sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18330738",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Word2Vec(sentences=corpus,sg=1,window=2, min_count=2, workers=4,iter=100,sample=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "115756f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:03<00:00, 12.61s/it]\n"
     ]
    }
   ],
   "source": [
    "#Train the Model\n",
    "for i in tqdm(range(5)):\n",
    "    model.train(sentences=suffle_data(corpus),epochs=50,total_examples=model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71fd5464",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model for future use \n",
    "model.save(\"w2v_model\")\n",
    "model=Word2Vec.load(\"w2v_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50636d9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('timid', 0.42580246925354004),\n",
       " ('helping', 0.42322707176208496),\n",
       " ('minor', 0.4203213155269623),\n",
       " ('irritation', 0.41295334696769714),\n",
       " ('lifted', 0.40578845143318176),\n",
       " ('firmly', 0.405303031206131),\n",
       " ('blessing', 0.39499086141586304),\n",
       " ('weapons', 0.39014092087745667),\n",
       " ('reluctant', 0.3876863121986389),\n",
       " ('ha', 0.38426440954208374)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test the model\n",
    "model.wv.most_similar(\"boy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce82c5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jetavana', 0.5554880499839783),\n",
       " ('perfected', 0.5323502421379089),\n",
       " ('sakyamuni', 0.5032818913459778),\n",
       " ('novices', 0.500219464302063),\n",
       " ('everywhere', 0.48540061712265015),\n",
       " ('dicegambler', 0.4842549264431),\n",
       " ('gotama', 0.48248612880706787),\n",
       " ('shines', 0.4748327136039734),\n",
       " ('follower', 0.46940064430236816),\n",
       " ('obsessed', 0.4689693748950958)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"buddha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937712e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
